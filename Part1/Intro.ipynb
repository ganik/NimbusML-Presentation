{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Tutorial 1: From Scikit-Learn to NimbusML\n\n\n## Goals:\n* Learn to write scripts with NimbusML components\n* Learn to boost your existing Scikit Learn scripts with NimbusML components\n\n## Why to use NimbusML ?\n* Used ML.NET before?\n* Used Scikit-Learn before?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Would you want this?\n<img align=\"middle\" src=\"https://notebooks.azure.com/ganik/libraries/test111/raw/data%2Fgoals.png\" height=700 />\n\n\n### NimbusML:\n<img align=\"middle\" src=\"https://notebooks.azure.com/ganik/libraries/test111/raw/data%2Fspeed.png\" width=550 height=550 />\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Lets start ...\n### Lets do all the imports:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cell 1\n\n# imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\n\n# NimbusML imports\nfrom nimbusml import Pipeline as NimbusPipeline, FileDataStream\nfrom nimbusml.linear_model import FastLinearBinaryClassifier\nfrom nimbusml.feature_extraction.text import NGramFeaturizer",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Set up train and test data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cell 2\n\nnp.random.seed(0)\n\n# Prepare train and test data\n# Twitter sentiment prediction\n# Subset of Kaggle Twitter positive/negative sentiment prediction https://www.kaggle.com/c/twitter-analysis  \n\ntrain_file = 'data/train.tsv'\ntest_file = 'data/test.tsv'\ndata_train = pd.read_csv(train_file, header=0, sep='\\t', encoding='latin-1') \ndata_test = pd.read_csv(test_file, header=0, sep='\\t', encoding='latin-1')\nprint(data_train[:10])\n\nlabel_column = 'Sentiment'\nfeature_column = 'SentimentText'\ntrain_X = data_train[feature_column].values.astype('U')\ntrain_y = data_train[label_column]\n\nk = 5000 # cut file into 500 lines\ntest_X = data_test[feature_column][:k].values.astype('U')\ntest_y = data_test[label_column][:k]",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   Sentiment                                      SentimentText\n0          0           is so sad for my APL friend.............\n1          0                   I missed the New Moon trailer...\n2          1                            omg its already 7:30 :O\n3          0  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n4          0       i think mi bf is cheating on me!!!       T_T\n5          0                          or i just worry too much?\n6          1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n7          0  Sunny Again        Work Tomorrow  :-|       TV...\n8          1    handed in my uniform today . i miss you already\n9          1           hmmmm.... i wonder how she my number @-)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Scikit script:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cell 3\n\n# Define pipeline, add transforms and classifier\npipe = Pipeline([\n('vect', CountVectorizer()),\n('tfidf', TfidfTransformer()),\n('clf', SGDClassifier(max_iter=10))])\n\n# Train pipeline\npipe.fit(train_X, train_y)\n\n# Get predictions\ntest_pred = pipe.predict(test_X)\n\nprint(test_pred[:10])\nprint(\"acc: %s\" % accuracy_score(test_pred, test_y))",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0 0 0 0 0 0 0 0 0 0]\nacc: 0.778\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Replace with NimbusML learner:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cell 4\n\n# Define pipeline, add transforms and classifier\npipe = Pipeline([\n('vect', CountVectorizer()),\n('tfidf', TfidfTransformer()),\n('clf', FastLinearBinaryClassifier())])\n\n# Train pipeline\npipe.fit(train_X, train_y)\n\n# Get predictions\ntest_pred = pipe.predict(test_X)\n\n#print(test_pred[:10])\nprint(\"acc: %s\" % accuracy_score(test_pred, test_y))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.\nUsing 1 thread to train.\nAutomatically choosing a check frequency of 1.\nAuto-tuning parameters: maxIterations = 285.\nAuto-tuning parameters: L2 = 2.679191E-05.\nAuto-tuning parameters: L1Threshold (L1/L2) = 1.\nUsing best model from iteration 19.\nNot training a calibrator because it is not needed.\nElapsed time: 00:00:01.6238504\nWarning: There is no NA value for type 'I8'. The missing key value will be mapped to the default value of 'I8'\nWarning: There is no NA value for type 'I8'. The missing key value will be mapped to the default value of 'I8'\nacc: 0.792\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### If you need to look up FastLinearBinaryClassifier details, here is extensive doc site:\nhttps://docs.microsoft.com/en-us/NimbusML\nAdditional TLC support alias: tlcsupp@microsoft.com\n\n\n### High level architecture\n\n* Memory passed in by ref\n* Memory passed back by copy\n\n<img align=\"middle\" src=\"https://notebooks.azure.com/ganik/libraries/test111/raw/data/architecture.png\" width=600 heigth=400 />\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Optimized NimbusML script:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cell 5\n\nschema = 'sep=tab col=Label:R4:0 col=SentimentText:TX:1 header=+'\ntrainDs = FileDataStream(train_file, schema)\ntestDs = FileDataStream(test_file, schema)\n\npipe = NimbusPipeline([\n  NGramFeaturizer() << {'Features':'SentimentText'},\n  FastLinearBinaryClassifier()])\n\n# Train pipeline\npipe.fit(trainDs)\n\n# Get predictions\ntest_pred = pipe.predict(testDs)\n\n#print(test_pred[:10])\nprint(\"acc: %s\" % accuracy_score(test_pred['PredictedLabel'][:k], test_y))",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Not adding a normalizer.\nUsing 1 thread to train.\nAutomatically choosing a check frequency of 1.\nAuto-tuning parameters: maxIterations = 285.\nAuto-tuning parameters: L2 = 2.679191E-05.\nAuto-tuning parameters: L1Threshold (L1/L2) = 1.\nUsing best model from iteration 17.\nNot training a calibrator because it is not needed.\nElapsed time: 00:00:06.9979151\nacc: 0.806\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Recap:\n* Created simple scikit learn script\n* Used NimbusML learner in scikit learn pipeline\n* Used NimbusML transformers and learner in NimbusML pipeline \n\nAnd if we would have run a whole dataset:\n<img align=\"middle\" src=\"https://notebooks.azure.com/ganik/libraries/test111/raw/data/scikit2NimbusML.png\"/>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}