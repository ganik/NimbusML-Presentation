{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Image Classification with PyTLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "* Introduce pre-trained models\n",
    "* Build a superhero image classifier with pre-trained models in PyTLC\n",
    "* Evaluate the classifier performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Pre-Trained Model?\n",
    "\n",
    "* A convolutional deep neural network (DNN) trained on a large dataset\n",
    "* Example large dataset: image-net 14M images and 1000 classes\n",
    "* It takes a lot of compute resources to train a DNN\n",
    "* Useful as image featurizer for small dataset\n",
    "\n",
    "<img src=\"files/pretrained_model_V2.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained DNN Models in PyTLC\n",
    "\n",
    "PyTLC comes with the following pre-trained DNN models:\n",
    "\n",
    "| DNN Model Name | Input Size | Output Size |\n",
    "| --- | --- | --- |\n",
    "| Resnet18 | 224 x 224 | 512 |\n",
    "| Resnet50 | 224 x 224 | 2048 |\n",
    "| Resnet101 | 224 x 224 | 2048 |\n",
    "| Alexnet | 227 x 227 | 4096 |\n",
    "\n",
    "* Pre-trained DNNs files are large and are not part of the PyTlc package wheel file\n",
    "* PyTlc automatically downloads the DNNs on first use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario: Superman vs Spiderman Classification\n",
    "\n",
    "<img src=\"files/vs.jpg\" width=300 height=300 />\n",
    "\n",
    "For this tutorial, we've picked superheroes because they're not in imagenet categories. Also, Superman and Spiderman both have red and blue costumes to make the detection harder.\n",
    "\n",
    "Let's build a Superman vs Spiderman classifier in PyTlc, without much deep learning or image processing knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports and helper functions\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from tutorial_helper import show_gallery, get_dimensions, label_counts, update_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1A\n",
    "# Load data\n",
    "data = pd.read_csv('files/data/data.csv')\n",
    "\n",
    "# Exploratory analysis\n",
    "print(data.head(), '\\n')\n",
    "print(label_counts(data), '\\n')\n",
    "print('Data shape: {}\\n'.format(data.shape))\n",
    "\n",
    "# Update image paths to use the faster disk\n",
    "update_image_paths(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1B\n",
    "# Sample images\n",
    "show_gallery(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1C\n",
    "# Explore image dimensions\n",
    "plt.scatter(*get_dimensions(data), s=5)\n",
    "plt.xlim(150,350)\n",
    "plt.ylim(150,350)\n",
    "plt.xlabel('Image Width')\n",
    "plt.ylabel('Image Height')\n",
    "plt.title('Image Dimensions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Extraction with Pre-Trained DNNs\n",
    "1. Build a pipeline to extract features\n",
    "2. Run the pipeline and examine the output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsoftml_scikit import Pipeline\n",
    "from microsoftml_scikit.linear_model import LogisticRegressionBinaryClassifier\n",
    "from microsoftml_scikit.feature_extraction.image import DnnFeaturizer, Loader, Resizer, PixelExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2A\n",
    "# Create feature extraction pipeline\n",
    "feature_extraction_pipeline = Pipeline([\n",
    "    # Load image from path\n",
    "    Loader() << {'Features':'ImagePath'},\n",
    "    \n",
    "    # Resize image to the correct inputs size of pretrained model\n",
    "    Resizer(image_width=xxx, image_height=xxxx, resizing='IsoPad'), # Replace xxx with the correct input size\n",
    "    \n",
    "    # Read pixel data as arrays\n",
    "    PixelExtractor(),\n",
    "    \n",
    "    # Run the pretrained DNN model\n",
    "    DnnFeaturizer(dnn_model='xxxx')]) # Replace xxxx with one of these: Resnet18 Resnet50 Resnet101 Alexnet \n",
    "\n",
    "# Extract features\n",
    "X_y = feature_extraction_pipeline.fit_transform(data.head(3))\n",
    "X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from microsoftml_scikit.utils.exports import img_export_pipeline\n",
    "# fig = img_export_pipeline(feature_extraction_pipeline,data['ImagePath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2B\n",
    "# Load pre-computed features\n",
    "X_y = pd.read_csv('files/data/xxxx.csv') # Replace xxxx with one of these: Resnet18 Resnet50 Resnet101 Alexnet\n",
    "update_image_paths(X_y)\n",
    "X_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Classifier\n",
    "1. Split data into 80% training set and 20% test set\n",
    "2. Train a logistic regression classifier\n",
    "3. Evaluate the classifier with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3A\n",
    "# Prepare train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(X_y,\n",
    "                               train_size=0.8,\n",
    "                               test_size=0.2, \n",
    "                               stratify=data.IsSuperman,\n",
    "                               random_state=xxxx) # Replace xxxx with a random positive integer\n",
    "print(label_counts(train, 'Training'))\n",
    "print(label_counts(test, 'Test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3B\n",
    "# Train a linear classifier\n",
    "X_train = train.iloc[:,:-2]\n",
    "y_train = train.IsSuperman\n",
    "\n",
    "clf = Pipeline([LogisticRegressionBinaryClassifier()])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3B\n",
    "# Test the classifier\n",
    "X_test = test.iloc[:,:-2]\n",
    "y_test = test.IsSuperman\n",
    "\n",
    "predictions, metrics = clf.test(X_test, y_test)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluate Classifier Performance\n",
    "1. Look at the predictions\n",
    "2. Calculate confusion matrix\n",
    "3. Examine the classifier mistakes\n",
    "4. Calculate accuracy with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4A\n",
    "# View Prediction\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4B\n",
    "# Join predictions with paths and original label\n",
    "path_and_label = test.reset_index()[['ImagePath', 'IsSuperman']].rename(columns={'IsSuperman': 'Label'})\n",
    "predictions = pd.concat([path_and_label, predictions], axis=1)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4C\n",
    "# View confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(predictions.Label, predictions.PredictedLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4D\n",
    "# Sort test images by predicted probability\n",
    "predictions['IsMistake'] = predictions.Label != predictions.PredictedLabel\n",
    "predictions.sort_values('Probability', inplace=True)\n",
    "show_gallery(predictions, num_images=100, randomize=False, add_prob=True, flag_mistakes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4E\n",
    "# View mistakes: Superman classified incorrectly\n",
    "superman_mistakes = predictions[(predictions.Label == 1) & predictions.IsMistake] \n",
    "show_gallery(superman_mistakes, add_name=True, add_prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4F\n",
    "# View mistakes: Spiderman classified incorrectly\n",
    "spiderman_mistakes = predictions[(predictions.Label == 0) & predictions.IsMistake] \n",
    "show_gallery(spiderman_mistakes, add_name=True, add_prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4G\n",
    "#Image('files/data/spiderman_111.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4H\n",
    "# Find accuracy with cross validation\n",
    "from microsoftml_scikit.model_selection import CV\n",
    "cross_validator = CV([LogisticRegressionBinaryClassifier()])\n",
    "cv_results = cross_validator.fit(X_y.iloc[:,:-2], X_y.IsSuperman, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4I\n",
    "# Metrics per fold\n",
    "cv_results['metrics'].set_index('Fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4J\n",
    "# Metrics summary statistics\n",
    "cv_results['metrics_summary'][['AUC', 'Accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "* Introduced what pre-trained DNNs are and how to use them in PyTLC\n",
    "* Built a superman vs spiderman image classifier without any deep learning or image processing knowledge requirement\n",
    "* The classifier achieves 93% accuracy with 5-fold cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
